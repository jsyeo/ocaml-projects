Loading sPL program ..
  let {int->int->int} f =  (fun {int->int->int} x       -> (fun {int->int} y -> x+y end) end)in {int->int} (fun {int->int} pa -> f 4 pa end) end
  as let {Int->Int->Int} f = fun {Int->Int->Int} x -> fun {Int->Int} y -> +[Var(x),Var(y)] end end in {Int->Int}fun {Int->Int} pa -> Appln[Var(f); Int(4);Var(pa)] end end
TYPE CHECKING program ..
 ==> inferred type Int->Int
TRANSFORMING ==> Appln[fun {(Int->Int->Int)->Int->Int} f -> fun {Int->Int} pa -> Appln[Var(f); Int(4);Var(pa)] end end; fun {Int->Int->Int} x -> fun {Int->Int} y -> +[Var(x),Var(y)] end end]
COMPILING ==> sp17d.svm
[LDF([],1,label_2),LDF([],1,label_0),CALL 1,DONE,
label_0:,LDF([(f,0)],1,label_1),RTN,
label_1:,LD (pa,1),LDCI 4,LD (f,0),CALL 2,RTN,
label_2:,LDF([(x,0)],1,label_3),RTN,
label_3:,LD (x,0),LD (y,1),PLUS,RTN]
TAIL-OPTIMIZE ==> 
[LDF([],1,label_2),LDF([],1,label_0),CALL 1,DONE,
label_0:,LDF([(f,0)],1,label_1),RTN,
label_1:,LD (pa,1),LDCI 4,LD (f,0),TAILCALL 2,
label_2:,LDF([(x,0)],1,label_3),RTN,
label_3:,LD (x,0),LD (y,1),PLUS,RTN]
LINKING ==> 
[LDF([],1,10),LDF([],1,4),CALL 1,DONE,
4:,LDF([(f,0)],1,6),RTN,
6:,LD (pa,1),LDCI 4,LD (f,0),TAILCALL 2,
10:,LDF([(x,0)],1,12),RTN,
12:,LD (x,0),LD (y,1),PLUS,RTN]
Loading sVM code from ..sp17d.svm
Loaded [LDF([],1,10),LDF([],1,4),CALL 1,DONE,LDF([(f,0)],1,6),RTN,LD (pa,1),LDCI 4,LD (f,0),TAILCALL 2,LDF([(x,0)],1,12),RTN,LD (x,0),LD (y,1),PLUS,RTN]
High Stack Memory Mark :1
Executing ==> CLOSURE
